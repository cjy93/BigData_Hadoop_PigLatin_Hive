Step 1) Create a permanent table with the schema inside
```
CREATE DATABASE IF NOT EXISTS nsdba2_superstore;
```
Drop table nsdba2_supertore.weblogs;
Drop table nsdba2_superstore.weblogs_temp;
```
USE nsdba2_superstore;
CREATE TABLE weblogs (
    l_datetime TIMESTAMP,
    l_ip STRING,  
    l_url STRING
)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY ','
LOCATION '/bakeinc/weblogs';
```

Step 2) Create a temporary table that is empty so we can load the weblog data into it
```
USE nsdba2_superstore;

CREATE EXTERNAL TABLE if not exists weblogs_temp(
    logstring STRING
);
```

```
LOAD DATA LOCAL INPATH '/home/cloudera/ca1/bdp/logfile_20190428_1914.tsv' 
INTO TABLE nsdba2_superstore.weblogs_temp;

```

Step 3) Using regular expression to extract the information required stated in the specs
To achieve the date, we use a substring.

On HIVE
To substitute to a variable and then calling it back later, refer to:
https://cwiki.apache.org/confluence/display/Hive/LanguageManual+VariableSubstitution
for regex.extract : http://dwgeek.com/hadoop-hive-regular-expression-functions-examples.html/
```
set dates = substring(logstring, 2, 19)
set ip = regexp_extract(substring(logstring,29),'(\\d{1,3}\.\\d{1,3}\.\\d{1,3}\.\\d{1,3})',1)
set url = regexp_extract(substring(logstring,29),'GET (.+) (HTTP/*)',1)

```

Step 4) Extract the columns from the logstring and then put into the table created in step 1 (type step 4 and step 3 tog in 1 cell in Hive)
```
INSERT OVERWRITE TABLE nsdba2_superstore.weblogs  
SELECT cast(${hiveconf:dates} AS TIMESTAMP), ${hiveconf:ip}, ${hiveconf:url}       
FROM nsdba2_superstore.weblogs_temp;

```


Step 5) Check if results printed inside HIVE
```
select * from nsdba2_superstore.weblogs;
```

Step 6) Check if the file is successfully output to the location /bakeinc/weblogs by searching the file search in HUE

